Данная дипломная работа посвящена изучению нескольких применений топологической регуляризации (целевой функции ) к практическим задачам обучения нейронных сетей. Такая функция потерь может быть применена к структурам из объектов обучения или к большой выборке объектов в целом, поскольку данные почти всегда имеют реляционную структуру. Мы тщательно исследуем последнюю идею
путем экспериментирования с генеративными моделями и определения применимости в первом случае.
В частности, мы оцениваем, как изменяются генеративные возможности GAN Вассерштейна при обучении 
с указанными топологическими регуляризациями для игрушечных двумерных наборов данных и стандартных наборов данных зрения:
MNIST и CelebA. В качестве дополнения, мы применяем топологическую регуляризацию к оптимизации
трехмерной реконструкции Gaussian Splatting, тем самым уменьшая количество нежелательных
компонент связанности в облаке точек. Мы также предлагаем простую и интерпретируемую метрику для измерения эффекта нашей регуляризации.